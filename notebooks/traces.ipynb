{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data && cd data && wget -c --retry-connrefused --tries=0 --timeout=50 http://aliopentrace.oss-cn-beijing.aliyuncs.com/v2018Traces/batch_task.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data && tar -xvzf batch_task.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/alibaba/clusterdata/blob/master/cluster-trace-v2018/fetchData.sh\n",
    "df = pd.read_csv('data/batch_task.csv', names=['task_name', 'instance_num', 'job_name', 'task_type', 'status', 'start_time', 'end_time', 'plan_cpu', 'plan_mem'])\n",
    "df['duration'] = df['end_time'] - df['start_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task name is:\n",
    "# a) containing dependencies (like 'J4_2_3' -> task 4 depends on 2 and 3)\n",
    "TASK_NAME_RE = re.compile('^[^_]*[A-Z](?P<task_id>\\d+)(_(?P<deps>[\\d+_]+))?(_Stg\\d+)?$') # Note: sometimes job ends with _Stg*\n",
    "# b) independent task (like 'task_LTE4NjUxMjg5NDY5MDI4NjAzNzU=')\n",
    "SINGLE_TASK_RE = re.compile('^task_[a-zA-Z0-9]+=*$')\n",
    "# c) 'MergeTask'\n",
    "\n",
    "# check that we cover all cases:\n",
    "assert df.task_name.apply(lambda f: TASK_NAME_RE.match(f) is not None or SINGLE_TASK_RE.match(f) is not None or f == 'MergeTask').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that 'MergeTask's are in fact independent tasks (i.e. the only task in a job)\n",
    "def get_merge_task_stats(df):\n",
    "    df = df[['job_name', 'task_name']].copy()\n",
    "    df['is_merge_task'] = df['task_name'] == 'MergeTask'\n",
    "    return df.groupby('job_name').agg(\n",
    "        count=pd.NamedAgg('task_name', 'count'),\n",
    "        mergeCount=pd.NamedAgg('is_merge_task', 'sum')\n",
    "    )\n",
    "\n",
    "assert len(get_merge_task_stats(df).query('mergeCount > 0 and count > 1')) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dependency info\n",
    "def get_task_index_and_deps(row):\n",
    "    task_name = row.task_name\n",
    "    if m := TASK_NAME_RE.match(task_name):\n",
    "        if m.group('deps'):\n",
    "            deps = [int(item) for item in m.group('deps').split('_') if item != '']\n",
    "        else:\n",
    "            deps = []\n",
    "        return int(m.group('task_id')), deps\n",
    "    else:\n",
    "        return 1, []\n",
    "\n",
    "df[['task_index', 'task_deps']] = df[['task_name']].apply(get_task_index_and_deps, result_type='expand', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['job_name', 'task_index', 'task_deps', 'duration', 'instance_num']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample job\n",
    "df[['job_name', 'task_index', 'task_deps', 'duration', 'instance_num']].query('job_name == \"j_3\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter jobs with 4 or more tasks\n",
    "jobs = df.groupby(\"job_name\").filter(lambda x: len(x) > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_names = jobs[\"job_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "sample_job_names = job_names.sample(n=10, random_state=333)\n",
    "sample_jobs = jobs[jobs[\"job_name\"].isin(sample_job_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_jobs[\"job_name\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_jobs.query('job_name == \"j_1849871\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "MAX_DURATION = 60\n",
    "INDENT = \"    \"\n",
    "DIRECTORY = \"data/generated_dags\"\n",
    "\n",
    "def task_template(task_data, job_data) -> (str, [str]):\n",
    "    dependencies = []\n",
    "    base_task = f\"\"\"\n",
    "task_{task_data['task_name']} = BashOperator(\n",
    "    task_id='{task_data['task_name']}',\n",
    "    bash_command='sleep {min(task_data['duration'], MAX_DURATION)}',\n",
    ")\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    for dependency_index in task_data[\"task_deps\"]:\n",
    "        dependency = None\n",
    "        for _, task in job_data.iterrows():\n",
    "            if task[\"task_index\"] == dependency_index:\n",
    "                dependency = task\n",
    "                break\n",
    "        assert dependency is not None\n",
    "        \n",
    "        dependency_template = f\"\"\"\n",
    "{dependency['task_name']} >> {task_data['task_name']}\n",
    "\"\"\".strip()\n",
    "        dependencies.append(dependency_template)\n",
    "    \n",
    "    return base_task, dependencies\n",
    "\n",
    "for job_name in sample_job_names:\n",
    "    job_data = sample_jobs[sample_jobs[\"job_name\"] == job_name].copy()\n",
    "    \n",
    "    \n",
    "    imports = f\"\"\"\n",
    "import pendulum\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "\n",
    "with DAG(\n",
    "    dag_id='{job_name}',\n",
    "    schedule_interval='*/5 * * * *',\n",
    "    start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),\n",
    "    catchup=False,\n",
    ") as dag:\n",
    "\"\"\".strip()\n",
    "    \n",
    "    templated_tasks = []\n",
    "    templated_dependencies = []\n",
    "    \n",
    "    for _, task_data in job_data.iterrows():\n",
    "        task_templated, dependencies_templated = task_template(task_data, job_data)\n",
    "        templated_tasks.append(task_templated)\n",
    "        templated_dependencies.extend(dependencies_templated)\n",
    "    \n",
    "    Path(DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "    Path(f'{DIRECTORY}/{job_name}').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(f'{DIRECTORY}/{job_name}.py', 'w+') as f:\n",
    "        f.write(imports)\n",
    "        \n",
    "        task_lines = \"\\n\".join(templated_tasks)\n",
    "        tasks_data = [f\"{INDENT}{line}\" for line in task_lines.split(\"\\n\")]\n",
    "        tasks = \"\\n\".join(tasks_data)\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        f.write(tasks)\n",
    "        \n",
    "        dependencies_lines = \"\\n\".join(templated_dependencies)\n",
    "        dependencies_data = [f\"{INDENT}{line}\" for line in dependencies_lines.split(\"\\n\")]\n",
    "        deps = \"\\n\".join(dependencies_data)\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        f.write(deps)\n",
    "    \n",
    "    shutil.copyfile(f'{DIRECTORY}/{job_name}.py', f'{DIRECTORY}/{job_name}/{job_name}.py')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
